---
layout: post
title:  "[ROS] Implement tf of ROS in c++"
date:   2022-04-11
category: ROS
---

## Intro.
ROS에서 tf에 관한 내용을 총 4개의 글로 작성하려고 한다. 이 글은 그 중 세 번째인 코드 구현이다. 

우리는 이미 [두 번째 시리즈](https://undol26.github.io/ros/2022/04/07/ros-tf2.html)에서 로봇 중심과 센서간의 기하학적 관계를 정의하였고 이를 urdf 파일로 정의하였다.

```xml
<?xml version="1.0" ?>
<!-- =================================================================================== -->
<!-- |    This document was autogenerated by xacro from robot.urdf.xacro               | -->
<!-- |    EDITING THIS FILE BY HAND IS NOT RECOMMENDED                                 | -->
<!-- =================================================================================== -->
<robot name="My Robot" xmlns:xacro="http://ros.org/wiki/xacro">
  <link name="base_link"/>
  <joint name="base_joint" type="fixed">
    <origin rpy="0 0 0" xyz="0 0 0"/>
    <parent link="base_link"/>
    <child link="chassis_link"/>
  </joint>

  <link name="chassis_link">
  </link>

  <!--cyglidar-->
  <link name="laser_link"/>
  <joint name="laser_joint" type="fixed">
    <origin rpy="0 0 0" xyz="0.5 0.15 0.74"/>
    <parent link="chassis_link"/>
    <child link="laser_link"/>
  </joint>

  <!--realsense-->
  <link name="camera_depth_optical_frame"/>
   <joint name="camera_depth_optical_frame_joint" type="fixed">
    <origin rpy="-1.57 0 -1.57" xyz="0.5 -0.15 0.74"/>
    <parent link="chassis_link"/>
    <child link="camera_depth_optical_frame"/>
  </joint>
</robot>
```

우리의 목표는
1. 각 센서축 (cyglidar, realsense link)을 기준으로 얻은 점들을 로봇 중심 축 (chassis_link)로 옮길 것이다.
2. 실제 코드에서 어떻게 구현하는가?
3. 구현한 값이 맞는지 어떻게 확인하는가?

## 코드 구현.
`cyglidar link` -> `chassis_link` 로 변환하는 것이나 `realsense link` -> `chassis_link`는 결국 같은 개념이다.

따라서 축 변환이 들어가 조금 더 복잡한 `realsense link` -> `chassis_link` 변환의 예제만 작성한다.

```cpp
// listener를 사용하기 위해 해더를 포함해준다.
#include <tf/transform_listener.h>

// create object
std::string m_CameraTF_Name = "camera_depth_optical_frame";
std::string m_BaseTF_Name = "chassis_link";

tf::TransformListener m_CameraListener;
tf::StampedTransform m_Camera2BaseTF;

try {
        Listener.waitForTransform(m_BaseTF_Name, m_CameraTF_Name, ros::Time(0), ros::Duration(1.5));
        Listener.lookupTransform(m_BaseTF_Name, m_CameraTF_Name, ros::Time(0), Src2BaseTF);
    }
catch (tf::TransformException ex) {
        ROS_ERROR("%s",ex.what());
        ros::Duration(1.0).sleep();
}

double TranslateX = Src2BaseTF.getOrigin().getX();
double TranslateY = Src2BaseTF.getOrigin().getY();
double TranslateZ = Src2BaseTF.getOrigin().getZ();
std::cout << "TranslateX: " << TranslateX << std::endl;
std::cout << "TranslateY: " << TranslateY << std::endl;
std::cout << "TranslateZ: " << TranslateZ << std::endl;

tf::Quaternion q = Src2BaseTF.getRotation();
std::cout << "qx: " << q.x() << std::endl;
std::cout << "qy: " << q.y() << std::endl;
std::cout << "qz: " << q.z() << std::endl;
std::cout << "qw: " << q.w() << std::endl << std::endl;

tf::Matrix3x3 m(q);
double roll, pitch, yaw;
m.getRPY(roll, pitch, yaw);
std::cout << "roll: " << roll << std::endl;
std::cout << "pitch: " << pitch << std::endl;
std::cout << "yaw: " << yaw << std::endl;
```

값을 확인하면 다음과 같다.

<img src="/public/img/ros/ros-tf1.png" alt=""/> 

`base` 축 기준으로 `lidar`는 (0.5,0.3,0.5), `realsense`는 (0.5, -0.3, 0.5)에 있었다.
`lidar`를 `base`로 옮기기 위해서는 `base`를 기준으로 (m_LidarTranslateX, m_LidarTranslateY, m_LidarTranslateZ) = (-0.5, -0.3, -0.5) 만큼 `이동(translate)`해야 한다. 카메라도 마찬가지.


- [http://wiki.ros.org/tf/Tutorials/Writing a tf listener (C++)](http://wiki.ros.org/tf/Tutorials/Writing%20a%20tf%20listener%20%28C%2B%2B%29)